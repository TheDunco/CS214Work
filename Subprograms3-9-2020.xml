<https://cs.calvin.edu/courses/cs/214/adams/pdfs/N04.Subprograms-Color.pdf>

[This material will not be on the midterm - but it will be on the final]

Categorizing functions: {
    Recall: The function set constructor: f(D) → R
    can be used to describe the operations in a language.
    This approach categorizes functions <domain (D)>, and <range (R)>.

    Example: C++ lets us use function notation to cast…
    int( real ) → int
    double( int ) → real

    But if we write a round() function:
    int round( double value) { return int(value + 0.5); }  
    
    then round() is also a member of: <(real) -> int> 
    and int() and round() obviously behave very differently...
}

Functions as: Mapping Rules: {
    The function constructor defines a function’s <specification>
    (i.e., it’s domain- and range-sets), but not its <behavior>

    (i.e., indicate the domain-to-range element mappings).

    Behavior can be defined via a domain-to-range mapping rule:
    Example: In C++, we can specify that: abs( int ) → int
    but to define the behavior of abs(), we need a rule:

    abs(v) = {v, if v >= 0;
            -v otherwise}
            
    A mapping rule must specify the range-value for each domain-value for which the funciton is defined.
}

Functions as: Algorithms: {
    •the function’s <name> An alternative way to specify behavior is to specify:
    •the function’s <parameters> 
    •a <rule> for computing the result, using the parameters.

    [See slides for Ada, Lisp, Smalltalk examples]

    Some like to view a HLL as a <syntax for writing [expressing] algoritms>
}

Functions and Operators: {
    Most functions can be defined as operators, and vice versa.
    Example: Ada provides an exponentiation operator <**> where C++ provides an exponentiation function <pow()>.
    So a 3rd-order polynomial can be expressed in C++ as

    y = a * pow(x, 3) + b * pow(x, 2) + c * x + d;

    Or in Ada...
    y = a * x ** 3 + b * x ** 2 + c * x + d;

    Superficially, functions and operators are equivalent:
    - The <argumetns> of a function ≡ the <operands> of an operator.
    - A function can be thought of as a <prefix operator>.
}

Functions as: Abstractions: {
    Others prefer to view functions as an abstraction mechanism:
    - the ability to <hide algorithm details behind a name>...
    
    Example: If a library provides a summation() function,
    it might use any of these algorithms:

    [See slides for iterative, recursive, and Gauss' formula examples]

    The name summation() is an
    abstraction that hides the details
    of the particular algorithm it uses.
}

Functions as: Subprograms: {
    [Algol family]
    Imperative HLLs divide functions into two categories: 
    − <Procedures>: subprograms that map: (P1 × P2 × ... × Pn) → ∅  [subprogram that returns nothing]
    − <Functions>: subprograms that map: (P1 × P2 × ... × Pn) → R ≠ ∅

    [See slides for standard names in different languages]

    We will describe subprograms mapping (D) → R as functions, 
    and describe subprograms mapping (D) → ∅ as procedures. 
}

Functions as: Messages: {
    OO languages view functions as <messages to objects>.
    The receiver of a message executes its <corresponding method>.
        − The result is controlled by the <receiver>, not the sender.

    Different OO languages use different syntax for messages...
    Example: To find the length of anArray, we send it a message:
    // C++
    anArray->length()
    // Java
    anArray.length
    // Smalltalk
    anArray size

    Messages are something like <postfix opearations>...
}

Subprogram Mechanisms: {
    To have a subprogram mechanism, a language must provide: 
    − A means of <defining> the subprogram (specifying its behavior); 
    − A means of <calling> the subprogram (or activating it).

    In programming languages, to define a thing is to: 
    − <allocate storage for that thing>; and 
    − <bind the things name to the address of that storage>.

    Example: This is a C++
    subprogram definition [on slides] because it:
    (i) reserves storage (for the function’s code); and
    (ii) binds the name summation to the first address in that storage.
}

Definitions vs. Declarations: {
    Where a definition binds a name to storage, 
    a <declaration> binds a name to a <type-constructor>.

    Example: This is a C++ declaration: [int summation (int n);]
    because it tells the compiler this about summation:
        summation(int) -> int
    allowing the compiler to type-check calls to the functions

    For a variable, declaration and definition are <the same>... 
    [int result;] [Declaring while also reserving storage]
    This statement reserves a word of memory, and binds the name result to the address of that word.

    For subprograms, declaration and definition <can be separated>.
}

C/C++ Family Pointers: {
    Implication of a function definition:
    a C/C++ function’s name is a <pointer to the starting address of the function>.

    [Pls see slides for examples and stuff]
    [typedef int* fptr(int) is a type that can store the address of a function]
    [similar to polymorphism]

    Classes use a similar table for <virtual/polymorphic functions>.
}


Subprogram definitions: {
    To allocate a subprogram’s storage, 4 items are needed:
    1. Its <parameters types> (data storage for values sent by the caller);
    2. Its <return-type> (data storage for the return value);
    3. Its <locals> (data storage for local variables); and
    4. Its <body> or statements (executable code storage).

    These are all provided by a subprogram’s definition.
    By contrast, a subprogram’s declaration requires only:

    1. Its <paraeters types> (i.e., its domain-set D); and
    2. Its <pareturn type> (i.e., its range-set R)
    This <function signature>: f(D) → R

    lets the compiler check calls to the function for correctness.
}

Imperative Examples: {
    Consider these imperative funciton definitions
    [See slides!]

    In each case, we have: <swap( int& x int& ) -> null> 

    This allows the compiler to check that in calls: swap(x, y);
    the arguments x and y are compatible with the parameters.

    [Allows compilers to determine if functions are being used correclty]
}

Subprograms: Lisp and Smalltalk: {
    A Lisp subprogram definition uses the <defun> function:
    When evaluated, defun parses
    the function that follows it and
    (assuming no errors) creates a
    symbol table entry for it.
    [See slides for example in Lisp]

    A Smalltalk subprogram must be <a member of a class>: [for object oriented, namespace for procedure oriented]
    On an accept event,
    Smalltalk parses the
    method and (assuming no
    errors) creates a symbol
    table entry for it.
    [See slides for example in Smalltalk]
}

Calling Subprograms: {
    In most languages, a subprogram is called by <naming it>.
    [C++, Ada, Modula2, FORTRAN examples on slides]

    Lisp functions must be called <as a valid expression> (following an o-parenthesis):

    Smalltalk requires that a message be sent to an object:
}

Issue: Parameterless Subprograms: {
    Must parentheses be given at calls to parameterless functions?

    C/C++: yes              doSomething()
    Ada: no                 doSomething;
    Modula-2: no            doSomething;
    Fortran: no             CALL doSomething
    Lisp: yes, but...       (doSomething)
    Smalltalk: No, but...   obj doSomething
}

Activations: {
    An activation <is a call to a subprogram>  and involves 3 steps:
    - Space for the subprogram’s data values is allocated on a special run-time stack;
    - The caller’s arguments are associated with the subprogram’s parameters;
    - Control is transferred from the caller to the starting address of the subprogram. 

    On Unix systems, the run-time stack grows “downward”

    The space for one subprogram’s
    data is called a stack frame, or <activation record>.
    [See stack on slides]
}

Why a Stack?: {
    [See slides for example!]

    The call-sequence uses <Last In First Out (LIFO)> behavior, so a stack is the appropriate data structure.
    Each activation’s parameters (n) and locals must be kept distinct.

    A stack is necessary in <any language that supports recursion>.
}

Memory Layout: {
    On Unix systems, a program’s data
    space is laid out something like this:

    •Space for static/global variables
    •The run-time stack for locals, 
    •The heap for dynamically allocated variables.

    This flexible design uses memory efficiently:
    A typical program only runs out of memory if
    − its stack overruns its heap (<runaway recursion>), or 
    − its heap overruns its stack (<memory leaks>).
}

Parameter Passing: {
    Parameters are allocated space <within the subprograms activation record> on the runtime stack.

    Before control is transferred to the
    subprogram, the call’s arguments are
    “associated with” these parameters. 

    Exactly how arguments get associated with parameters
    depends on the parameter passing mechanism being used.

    There are four general mechanisms: <call by- value, reference, copy-restor, name>
}

Call By Value Parameters: {
    … are <variables> into which their arguments are <copied>. 
    − Changing a parameter doesn’t affect its argument’s value. 
    − This is the default mechanism in most languages. 
    − This is the only mechanism in C, Lisp, Java, Smalltalk, ...
    [See slides for the language]
    [In big structures, it's still going to be call by reference]
}

When function summ() is called: {
    [Everything on slides!]
}

Call-by-Reference Parameters: {
    … are <pointers> storing <the address of the arguments>, that are auto-dereferenced whenever they are accessed.

    − The parameter is an alias for the argument. 
    − Changing the parameter’s value changes the argument’s value.

    Smalltalk and Lisp
    implicitly provide
    call-by-reference,
    because “variables”
    are actually pointers
    to dynamic objects.
    Java is complicated...

    [See slides for C++ and Ada examples]
}

When swap() is called: {
    [All on slide again, example]
}

Implementing Call-by-Reference?: {
    Stroustrup’s first C++ “compiler” just produced C code,
    so if C only provides the call-by-value mechanism,
    how can it handle the C++ call-by-reference mechanism?

    1. At the call, replace arguments
    with <addresses>:

    2. In the declaration and definition, replace reference parameters with <pointers>:

    3. Within the function definition, <dereference> each access to the parameter

    Any compiler can implement call-byreference this way.

    [See slides for examples]
}

Call-by-Copy-Restore Parameters: {
    … store <both the value and the address of their arguments>.

    − Within the subprogram, parameter accesses <use the local values> 
    − When the subprogram terminates, the local value is __________ into the corresponding argument. 
    − More time-efficient then call-by-reference for heavily-used
    parameters (avoids slow pointer-dereferencing). 
    − Ada’s ___________ parameters may use copy-restore...
} (big oof)

Get() Exmaple: {[On slide]}

Aliasing: {
    Copy-restore parameters behave the same as reference
    parameters, so long as the parameter is not an <alias> for a
    non-local that is accessed within the same subprogram.

    [See slide for code]

    What is output, if param uses:
    procedure aliasExample (param: in out integer) is
    begin
    param:= 1;
    a:= 2;
    end get;
    - call-by-reference?
    - call-by-value-restore?
    To avoid this, Ada <forbids aliasing>.
}

Call-by-Name Parameters: {
    [If you have code that represnts a variable that would be passed as a call by name parameter,
    it won't get used until the thing gets evaluated]
    [If statements in Clojure/Lisp, also allows partial execution]

    1. Copy the body of the subprogram;
    2. In the copy, substitute the arguments for the parameters;
    3. Substitute the resulting copy for the call;

    The result is the call-by-name mechanism (aka <macro-substitution>).

    − Call-by-name originated with Algol-60. − By replacing the function-call with the altered body, call-by-name:
     <Improves time-efficiency> by eliminating the call and the RTS overhead; but
     <Decreases space-efficiency> by increasing the size of the program.
}

At each call to swap(): {
    The resulting code is ________, but without the overhead of
pushing a stack-frame, setting parameters, … it runs _____.

}
